## Traditional Supervised Learning

features (input attributes: $\vec{x}$ 

target $t$: $f(\vec{x})$

labeled data: $\langle\vec{x}, f(\vec{x})\rangle$



#### Abstract view

target function $f$: $X \rightarrow Y$

goal: hypothesis $h$: $X \rightarrow Y$

**inductive bias** is present 



The output of the process is a **pattern classifier**

Full Process: $\vec{x} \rightarrow h(\vec{x}) \rightarrow c_i$



#### Apparent vs. True Error

**true error rate**: theoretical probability of error on future examples, we don't actually know what this is, at most we make a very close estimation

**apparent error rate**: the error rate on the training data

How to assess performance?

- use separate training, test data sets
- select test data randomly
  - **holdout method**: randomly divide data into a:
    1. training set
    2. test set, which is "held out"
  - **k-fold cross-validation**:
    1. divide data into k equal parts
    2. use k-1 parts for training, remaining part for testing
    3. do this k times, and take average performance

95% confidence interval using sample error $E$

$ E_x \pm 1.96\sqrt{ \frac{E_{x}(1 - E_{x})}{n} }$



#### Class-Specific Measures

sensitivity($c_i$)  = # correctly classified as $c_i$ / # $c_i$ occurring

specificity($c_i$) = # correctly classified as not $c_i$ / # not $c_i$ occurring



#### Random: Brain

Critical for learning:

- cerebral cortex
- hippocampus



## Neural Networks

### **Network Architectures**

- feedforward (not necessarily layered)
- recurrent networks
  - forwards
  - backwards
  - lateral

1. 

2. 
3. Learning Rule
   - weight changes as function of local activity

**Pattern Classification**

def: given a set of data in two classes, separates data into separate classes. defines a "decision surface" in the input space

a **decision surface** would typically be a curve, plane, or hyperplane. could even just be an ellipse around the data

## Perceptron

def: a pattern classifier

given an input vector: $\vec{a}$

can represent a linear decision surface such as:

- line
- plane
- hyperplane

$in_r =$ dot product ex in slides: $3 * 1 + 0 * 5 + (-1) * 1$

$a_r =$ if $in_r$ is above threshold, 1, else 0

